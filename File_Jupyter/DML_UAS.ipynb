{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb1b686a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import fitz  # PyMuPDF\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "245c75be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Konfigurasi Path ---\n",
    "# Disesuaikan dengan struktur folder baru yang memiliki subfolder PDF dan XML\n",
    "# --- Konfigurasi Path ---\n",
    "BASE_PATH = r'D:\\Jupyter File\\make-data-count-finding-data-references'\n",
    "TEST_FOLDER = os.path.join(BASE_PATH, 'test')\n",
    "TEST_XML_FOLDER = os.path.join(TEST_FOLDER, 'XML')\n",
    "TEST_PDF_FOLDER = os.path.join(TEST_FOLDER, 'PDF')\n",
    "SAMPLE_SUBMISSION_PATH = os.path.join(BASE_PATH, 'sample_submission.csv')\n",
    "OUTPUT_FILE = 'submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74f8692f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Fungsi Helper untuk Ekstraksi Teks ---\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Membersihkan teks dari spasi berlebih dan karakter aneh.\"\"\"\n",
    "    text = re.sub(r'-\\n', '', text)  # Menghapus tanda hubung di akhir baris\n",
    "    text = re.sub(r'\\n', ' ', text)   # Mengganti baris baru dengan spasi\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Mengganti spasi ganda dengan spasi tunggal\n",
    "    return text.strip()\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Membaca dan mengekstrak teks dari file PDF.\"\"\"\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        text = \"\"\n",
    "        for page in doc:\n",
    "            text += page.get_text()\n",
    "        doc.close()\n",
    "        return clean_text(text.lower())\n",
    "    except Exception as e:\n",
    "        print(f\"Gagal membaca PDF {pdf_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def extract_text_from_xml(xml_path):\n",
    "    \"\"\"Membaca dan mengekstrak teks dari file XML.\"\"\"\n",
    "    try:\n",
    "        tree = ET.parse(xml_path)\n",
    "        root = tree.getroot()\n",
    "        text_parts = [elem.text for elem in root.iter() if elem.text]\n",
    "        text = ' '.join(text_parts)\n",
    "        return clean_text(text.lower())\n",
    "    except Exception as e:\n",
    "        print(f\"Gagal membaca XML {xml_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def get_article_text(article_id, xml_folder, pdf_folder):\n",
    "    \"\"\"\n",
    "    Mendapatkan teks lengkap dari artikel dari subfolder yang benar.\n",
    "    Memprioritaskan file XML, jika tidak ada, gunakan PDF.\n",
    "    \"\"\"\n",
    "    xml_path = os.path.join(xml_folder, f\"{article_id}.xml\")\n",
    "    pdf_path = os.path.join(pdf_folder, f\"{article_id}.pdf\")\n",
    "    \n",
    "    if os.path.exists(xml_path):\n",
    "        return extract_text_from_xml(xml_path)\n",
    "    elif os.path.exists(pdf_path):\n",
    "        return extract_text_from_pdf(pdf_path)\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de82b114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Pola Regular Expression (Regex) yang Diperluas ---\n",
    "DOI_REGEX = r'\\b(10\\.\\d{4,9}/[-._;()/:A-Z0-9]+)\\b'\n",
    "\n",
    "ACCESSION_ID_REGEX = {\n",
    "    'GEO': r'\\b(GSE\\d{4,})\\b',\n",
    "    'SRA': r'\\b(SRP\\d{6,}|ERP\\d{6,}|DRP\\d{6,})\\b',\n",
    "    'PDB': r'\\b(PDB\\s\\w{4}|\\d\\w{3})\\b',\n",
    "    'ARRAY_EXPRESS': r'\\b(E-\\w{4}-\\d+)\\b',\n",
    "    'DRYAD': r'\\b(dryad\\.\\w+\\.?\\w+)\\b',\n",
    "    'FIGSHARE': r'\\b(figshare\\.\\w+\\.?\\w+)\\b',\n",
    "    'ZENODO': r'\\b(zenodo\\.\\d+)\\b',\n",
    "    'GENBANK': r'\\b([A-Z]{1,2}\\d{5,})\\b'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ad29ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Logika Klasifikasi Berbasis Kata Kunci ---\n",
    "SECONDARY_KEYWORDS = [\n",
    "    'obtained from', 'reused', 'retrieved from', 'acquired from', \n",
    "    'downloaded from', 'accessed from', 'taken from', 'derived from',\n",
    "    'diperoleh dari', 'digunakan kembali', 'diambil dari', 'diunduh dari', 'diakses dari'\n",
    "]\n",
    "\n",
    "PRIMARY_KEYWORDS = [\n",
    "    'data are available', 'can be accessed from', 'available from', 'deposited in',\n",
    "    'generated as part of this paper', 'data for this study', 'are provided',\n",
    "    'data we used in this publication', 'data necessary for confirming',\n",
    "    'data tersedia', 'dapat diakses dari', 'tersedia dari', 'disimpan di',\n",
    "    'dihasilkan sebagai bagian dari makalah ini', 'data untuk penelitian ini'\n",
    "]\n",
    "\n",
    "def classify_citation(ds_id, full_text):\n",
    "    \"\"\"\n",
    "    Mengklasifikasikan kutipan sebagai Primary atau Secondary berdasarkan kata kunci.\n",
    "    \"\"\"\n",
    "    context_window = 250\n",
    "    for match in re.finditer(re.escape(ds_id), full_text, re.IGNORECASE):\n",
    "        start, end = match.span()\n",
    "        context = full_text[max(0, start - context_window):end + context_window]\n",
    "        for keyword in SECONDARY_KEYWORDS:\n",
    "            if keyword in context:\n",
    "                return 'Secondary'\n",
    "        for keyword in PRIMARY_KEYWORDS:\n",
    "            if keyword in context:\n",
    "                return 'Primary'\n",
    "    return 'Primary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0581e6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memulai proses penambangan kutipan data...\n",
      "Ditemukan 1 artikel unik di dalam folder test.\n",
      "Memproses artikel 1/1: 10\n",
      "Tidak ada dataset yang ditemukan. Membuat file submission kosong.\n",
      "\n",
      "Proses selesai. File submission telah dibuat di: submission.csv\n",
      "Total prediksi yang dibuat: 0\n",
      "Contoh isi file submission:\n",
      "Empty DataFrame\n",
      "Columns: [row_id, article_id, dataset_id, type]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# --- Logika Utama ---\n",
    "def main():\n",
    "    \"\"\"Fungsi utama untuk menjalankan proses deteksi dan klasifikasi.\"\"\"\n",
    "    print(\"Memulai proses penambangan kutipan data...\")\n",
    "    \n",
    "    # Memastikan folder-folder yang dibutuhkan ada\n",
    "    if not os.path.isdir(TEST_FOLDER):\n",
    "        print(f\"Error: Folder utama '{TEST_FOLDER}' tidak ditemukan.\")\n",
    "        return\n",
    "\n",
    "    # Mendapatkan daftar ID artikel dari kedua subfolder (PDF dan XML)\n",
    "    pdf_files = os.listdir(TEST_PDF_FOLDER) if os.path.isdir(TEST_PDF_FOLDER) else []\n",
    "    xml_files = os.listdir(TEST_XML_FOLDER) if os.path.isdir(TEST_XML_FOLDER) else []\n",
    "    \n",
    "    test_article_ids = sorted(list(set([fn.split('.')[0] for fn in pdf_files + xml_files])))\n",
    "    \n",
    "    if not test_article_ids:\n",
    "        print(f\"Error: Tidak ada file yang ditemukan di dalam subfolder '{TEST_PDF_FOLDER}' atau '{TEST_XML_FOLDER}'.\")\n",
    "        return\n",
    "        \n",
    "    print(f\"Ditemukan {len(test_article_ids)} artikel unik di dalam folder test.\")\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    for i, article_id in enumerate(test_article_ids):\n",
    "        if (i + 1) % 50 == 0 or i == len(test_article_ids) - 1:\n",
    "            print(f\"Memproses artikel {i+1}/{len(test_article_ids)}: {article_id}\")\n",
    "            \n",
    "        full_text = get_article_text(article_id, TEST_XML_FOLDER, TEST_PDF_FOLDER)\n",
    "        if not full_text:\n",
    "            continue\n",
    "            \n",
    "        found_datasets = set()\n",
    "\n",
    "        # Cari DOI\n",
    "        for match in re.finditer(DOI_REGEX, full_text, re.IGNORECASE):\n",
    "            dataset_id = match.group(0).strip('.,')\n",
    "            found_datasets.add(dataset_id)\n",
    "            \n",
    "        # Cari Accession IDs\n",
    "        for pattern in ACCESSION_ID_REGEX.values():\n",
    "            for match in re.finditer(pattern, full_text, re.IGNORECASE):\n",
    "                found_datasets.add(match.group(0).strip('.,'))\n",
    "\n",
    "        for ds_id in found_datasets:\n",
    "            citation_type = classify_citation(ds_id, full_text)\n",
    "            predictions.append({\n",
    "                'article_id': article_id,\n",
    "                'dataset_id': ds_id,\n",
    "                'type': citation_type\n",
    "            })\n",
    "\n",
    "    # Buat file submission\n",
    "    if not predictions:\n",
    "        print(\"Tidak ada dataset yang ditemukan. Membuat file submission kosong.\")\n",
    "        submission_df = pd.DataFrame(columns=['row_id', 'article_id', 'dataset_id', 'type'])\n",
    "    else:\n",
    "        submission_df = pd.DataFrame(predictions).drop_duplicates()\n",
    "        submission_df.reset_index(drop=True, inplace=True)\n",
    "        submission_df['row_id'] = submission_df.index\n",
    "        submission_df = submission_df[['row_id', 'article_id', 'dataset_id', 'type']]\n",
    "\n",
    "    submission_df.to_csv(OUTPUT_FILE, index=False)\n",
    "    \n",
    "    print(f\"\\nProses selesai. File submission telah dibuat di: {OUTPUT_FILE}\")\n",
    "    print(f\"Total prediksi yang dibuat: {len(submission_df)}\")\n",
    "    print(\"Contoh isi file submission:\")\n",
    "    print(submission_df.head())\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
